{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UnifiedFlowNet(nn.Module):\n",
    "    def __init__(self, latent_dim, cond_dim=None, drop_prob=0.1):\n",
    "        \"\"\"\n",
    "        latent_dim: latent z 的通道数\n",
    "        cond_dim: 如果 None，就和 latent_dim 相同；否则可用来添加其他条件（如标签维度）\n",
    "        drop_prob: 进行无条件训练的概率 r\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.cond_dim = cond_dim or latent_dim\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        # 输入通道 = z_t + t_map + 条件 z_c\n",
    "        in_ch = latent_dim + 1 + self.cond_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),   nn.ReLU(),\n",
    "            nn.Conv2d(64, latent_dim, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, z_t, t, z_c=None):\n",
    "        B, C, H, W = z_t.shape\n",
    "\n",
    "        # 1) 时间通道\n",
    "        t_map = t.view(B,1,1,1).expand(B,1,H,W)\n",
    "\n",
    "        # 2) 条件通道：classifier-free guidance\n",
    "        if z_c is None:\n",
    "            # 强制无条件\n",
    "            z_c_in = torch.zeros(B, self.cond_dim, H, W, device=z_t.device)\n",
    "        else:\n",
    "            # 以 drop_prob 随机丢弃\n",
    "            mask = (torch.rand(B, device=z_t.device) < self.drop_prob).float()\n",
    "            mask = mask.view(B,1,1,1)\n",
    "            z_c_keep = z_c\n",
    "            z_c_zero = torch.zeros_like(z_c)\n",
    "            z_c_in = z_c_keep * (1-mask) + z_c_zero * mask\n",
    "\n",
    "        # 拼接输入\n",
    "        inp = torch.cat([z_t, t_map, z_c_in], dim=1)\n",
    "        v_pred = self.net(inp)\n",
    "        return v_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnifiedFlowNet(latent_dim=16, cond_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for imgs, _ in loader:\n",
    "        # 编码\n",
    "        z_data = vae.encode(imgs)            # [B,C,H,W]\n",
    "        z_noise = torch.randn_like(z_data)   # 噪声端\n",
    "\n",
    "        # 随机插值和 t\n",
    "        t = torch.rand(B, device=device)\n",
    "        z_t = (1-t_b)*z_data + t_b*z_noise\n",
    "        v_true = z_noise - z_data\n",
    "\n",
    "        # forward: 既可能是有条件，也可能是无条件\n",
    "        v_pred = model(z_t, t, z_c=z_data)\n",
    "\n",
    "        loss = F.mse_loss(v_pred, v_true)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(model, vae, mode='conditional', z_c=None, steps=20, batch_size=4):\n",
    "    model.eval()\n",
    "    latent_dim = model.latent_dim\n",
    "    # 初始 z\n",
    "    z = torch.randn(batch_size, latent_dim, H, W, device=device)\n",
    "    # 如果 conditional 模式，z_c 必须给定；否则为 None\n",
    "    z_c_input = z_c if mode=='conditional' else None\n",
    "\n",
    "    for i in range(steps):\n",
    "        t = 1.0 - i/steps\n",
    "        t_vec = torch.full((batch_size,), t, device=device)\n",
    "        v = model(z, t_vec, z_c=z_c_input)\n",
    "        z = z - (1.0/steps) * v\n",
    "\n",
    "    x_out = vae.decode(z).clamp(0,1)\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 z_data 与 z_noise 都是 [B, C, H, W]\n",
    "z_data = torch.randn((2,16,32,32))           # [B,C,H,W]\n",
    "B, C, H, W = z_data.shape\n",
    "z_noise = torch.randn_like(z_data)   # 噪声端\n",
    "\n",
    "# 1. 采样 t 并构造可广播的 t_b\n",
    "t = torch.rand(B, device=device)               # [B]\n",
    "t_b = t.view(B, 1, 1, 1)                       # [B,1,1,1]\n",
    "\n",
    "# 2. 插值\n",
    "z_t = (1.0 - t_b) * z_data + t_b * z_noise     # [B,C,H,W]\n",
    "\n",
    "# 3. 真实速度场\n",
    "v_true = z_noise - z_data                      # [B,C,H,W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_pred = model(z_t, t, z_c=z_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(v_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(v_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, C, H, W = z_t.shape\n",
    "z_c = torch.randn((2,16,32,32))\n",
    "cond_dim = 16\n",
    "drop_prob = 0.5\n",
    "# 1) 时间通道\n",
    "t_map = t.view(B,1,1,1).expand(B,1,H,W)\n",
    "\n",
    "# 2) 条件通道：classifier-free guidance\n",
    "if z_c is None:\n",
    "    # 强制无条件\n",
    "    z_c_in = torch.zeros(B, cond_dim, H, W, device=z_t.device)\n",
    "else:\n",
    "    # 以 drop_prob 随机丢弃\n",
    "    mask = (torch.rand(B, device=z_t.device) < drop_prob).float()\n",
    "    mask = mask.view(B,1,1,1)\n",
    "    z_c_keep = z_c\n",
    "    z_c_zero = torch.zeros_like(z_c)\n",
    "    z_c_in = z_c_keep * (1-mask) + z_c_zero * mask\n",
    "\n",
    "# 拼接输入\n",
    "inp = torch.cat([z_t, t_map, z_c_in], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 33, 32, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-04 03:39:48,199] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: warning: librt.so.1, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: warning: libpthread.so.0, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: warning: libstdc++.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: warning: libm.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::runtime_error::~runtime_error()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__gxx_personality_v0@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::tellp()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::steady_clock::now()@GLIBCXX_3.4.19'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_replace_aux(unsigned long, unsigned long, unsigned long, char)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for bool@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_logic_error(char const*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::logic_error@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::~locale()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_end_catch@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::logic_error::~logic_error()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__si_class_type_info@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new[](unsigned long)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak_hard()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::basic_streambuf(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned short@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::resize(unsigned long, char)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char const*@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ctype<char>::_M_widen_init() const@GLIBCXX_3.4.11'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_invalid_argument(char const*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::operator=(std::locale const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_free_exception@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::notify_one()@GLIBCXX_3.4.11'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::~Init()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_pure_virtual@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::flush()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__class_type_info@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_rethrow@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_fstream<char, std::char_traits<char> >::~basic_fstream()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::compare(char const*) const@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::system_clock::now()@GLIBCXX_3.4.19'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Hash_bytes(void const*, unsigned long, unsigned long)@CXXABI_1.3.5'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long long>(long long)@GLIBCXX_3.4.9'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char*@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_Prime_rehash_policy::_M_need_rehash(unsigned long, unsigned long, unsigned long) const@GLIBCXX_3.4.18'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::out_of_range@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long)@GLIBCXX_3.4.9'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::~ios_base()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::range_error::~range_error()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::~__basic_file()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_acquire@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<bool>(bool)@GLIBCXX_3.4.9'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::overflow_error@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::range_error@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_filebuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete[](void*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(unsigned long, char, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_transfer(std::__detail::_List_node_base*, std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::replace(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::exception@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_M_destroy(std::allocator<wchar_t> const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream& std::istream::_M_extract<double>(double&)@GLIBCXX_3.4.9'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::basic_ifstream(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(std::string const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new(unsigned long)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::domain_error@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char, unsigned long) const@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::put(char)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for int@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_alloc()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_thread_atexit@CXXABI_1.3.7'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int*@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::~basic_ifstream()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::Init()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::condition_variable()@GLIBCXX_3.4.11'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::basic_filebuf()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::domain_error::~domain_error()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cerr@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::invalid_argument@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void*@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(std::string const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_rebalance_for_erase(std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_hook(std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_unhook()@GLIBCXX_3.4.15'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::_M_sync(char*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<char, std::char_traits<char> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `log2f@GLIBC_2.2.5'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::exception::~exception()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_create(unsigned long, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::is_open() const@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_istringstream()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::swap(std::string&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::basic_streambuf(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::init(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_cast()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::clear(std::_Ios_Iostate)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::operator=(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long*@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete(void*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(int)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<wchar_t, std::char_traits<wchar_t> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::runtime_error@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_insert_and_rebalance(bool, std::_Rb_tree_node_base*, std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_stringstream()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long>(long)@GLIBCXX_3.4.9'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::get()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long long@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::operator<< <std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::out_of_range::~out_of_range()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::length_error::~length_error()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::__ostream_insert<char, std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*, long)@GLIBCXX_3.4.9'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::invalid_argument::~invalid_argument()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::swap(std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cout@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long long>(unsigned long long)@GLIBCXX_3.4.9'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<void const*>(void const*)@GLIBCXX_3.4.9'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::underflow_error@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::out_of_range@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_allocate_exception@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void const*@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::init(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::reserve(unsigned long)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_begin_catch@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::open(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_M_sync(wchar_t*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::getline(char*, long, char)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::getline<char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::basic_string<char, std::char_traits<char>, std::allocator<char> >&, char)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::~condition_variable()@GLIBCXX_3.4.11'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::insert(unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned char@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::ios_base()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_out_of_range(char const*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::overflow_error::~overflow_error()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_length_error(char const*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_system_error(int)@GLIBCXX_3.4.11'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ofstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<double>(double)@GLIBCXX_3.4.9'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::operator=(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long long@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_release@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_throw@CXXABI_1.3'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::underflow_error::~underflow_error()@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::length_error@GLIBCXX_3.4'\n",
      "/opt/conda/envs/pytorch/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::~basic_filebuf()@GLIBCXX_3.4'\n",
      "collect2: error: ld returned 1 exit status\n",
      "/opt/conda/envs/pytorch/lib/python3.12/site-packages/generative/networks/layers/vector_quantizer.py:86: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/opt/conda/envs/pytorch/lib/python3.12/site-packages/generative/networks/layers/vector_quantizer.py:124: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "import os, json, wandb, torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from monai import transforms, data\n",
    "from monai.data import DataLoader, DistributedSampler\n",
    "from monai.utils import set_determinism\n",
    "from tqdm import tqdm\n",
    "from generative.losses import PatchAdversarialLoss, PerceptualLoss\n",
    "from generative.networks.nets import  PatchDiscriminator\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json_path = './json/train.json'\n",
    "with open(train_json_path) as f:\n",
    "    train_files = json.load(f)\n",
    "val_json_path = './json/val.json'\n",
    "with open(val_json_path) as f:\n",
    "    val_files = json.load(f)\n",
    "train_batchsize  = 1\n",
    "\n",
    "transforms_1mm = transforms.Compose(\n",
    "    [transforms.Spacingd(keys=[\"image\"], pixdim=(1, 1, 1), mode=(\"bilinear\")),\n",
    "    transforms.Spacingd(keys=[\"brainmask\"], pixdim=(1, 1, 1), mode=(\"nearest\")),\n",
    "    transforms.SpatialPadd(keys=[\"image\",\"brainmask\"], spatial_size=(160, 160, 128)),\n",
    "    transforms.CropForegroundd(keys=[\"image\"], source_key=\"brainmask\",allow_smaller=False),\n",
    "    transforms.DeleteItemsd(keys=[\"brainmask\"]),\n",
    "    transforms.RandSpatialCropd(keys=[\"image\"], roi_size=(80, 80, 64),max_roi_size = (100, 100, 80), random_size=True),\n",
    "    transforms.Resized(keys=[\"image\"], spatial_size=(80, 80, 64), size_mode = 'all', mode='bilinear'),\n",
    "    ]\n",
    ")\n",
    "transforms_2mm = transforms.Compose(\n",
    "    [transforms.Spacingd(keys=[\"image\"], pixdim=(2, 2, 2), mode=(\"bilinear\")),\n",
    "    transforms.Spacingd(keys=[\"brainmask\"], pixdim=(2, 2, 2), mode=(\"nearest\")),\n",
    "    transforms.SpatialPadd(keys=[\"image\",\"brainmask\"], spatial_size=(80, 80, 64)),\n",
    "    transforms.CropForegroundd(keys=[\"image\"], source_key=\"brainmask\",allow_smaller=False),\n",
    "    transforms.DeleteItemsd(keys=[\"brainmask\"]),\n",
    "    transforms.Resized(keys=[\"image\"], spatial_size=80, size_mode = 'longest', mode='bilinear'),\n",
    "    transforms.CenterSpatialCropd(keys=[\"image\"], roi_size=(80, 80, 64)),\n",
    "    transforms.SpatialPadd(keys=[\"image\"], spatial_size=(80, 80, 64)),\n",
    "    ]\n",
    ")\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.CopyItemsd(keys=[\"image\"], names=[\"path\"]),\n",
    "        transforms.LoadImaged(keys=[\"image\",\"brainmask\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\",\"brainmask\"]),\n",
    "        transforms.EnsureTyped(keys=[\"image\",\"brainmask\"]),\n",
    "        transforms.Orientationd(keys=[\"image\",\"brainmask\"], axcodes=\"RAS\"),\n",
    "        # transforms.RandAffined(\n",
    "        #     keys=[\"image\",\"brainmask\"],\n",
    "        #     rotate_range=(-np.pi / 36, np.pi / 36),\n",
    "        #     translate_range=(-1, 1),\n",
    "        #     scale_range=(-0.05, 0.05),\n",
    "        #     padding_mode=\"zeros\",\n",
    "        #     prob=0.5,\n",
    "        # ),\n",
    "        transforms.CropForegroundd(\n",
    "            keys=[\"image\", \"brainmask\"],\n",
    "            source_key=\"brainmask\",\n",
    "            allow_smaller=False,\n",
    "        ),\n",
    "        transforms.ResizeWithPadOrCropd(keys=[\"image\",\"brainmask\"], spatial_size=(192, 192, 141)),\n",
    "        transforms.ScaleIntensityRangePercentilesd(keys=\"image\", lower=0.5, upper=99.5, b_min=0, b_max=1,clip=True ),#, relative=True\n",
    "        # transforms.OneOf([transforms_1mm, transforms_2mm]),\n",
    "    ]\n",
    ")\n",
    "train_ds = data.Dataset(data=train_files, transform=train_transforms)\n",
    "# sampler_train = DistributedSampler(train_ds, num_replicas=4, rank=rank)\n",
    "train_loader = DataLoader(train_ds, batch_size=train_batchsize, shuffle=False, num_workers=8, persistent_workers=True, drop_last=True, sampler=None)\n",
    "\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.CopyItemsd(keys=[\"image\"], names=[\"path\"]),\n",
    "        transforms.LoadImaged(keys=[\"image\",\"brainmask\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\",\"brainmask\"]),\n",
    "        transforms.EnsureTyped(keys=[\"image\",\"brainmask\"]),\n",
    "        transforms.Orientationd(keys=[\"image\",\"brainmask\"], axcodes=\"RAS\"),\n",
    "        transforms.CropForegroundd(\n",
    "            keys=[\"image\", \"brainmask\"],\n",
    "            source_key=\"brainmask\",\n",
    "            allow_smaller=False,\n",
    "        ),\n",
    "        transforms.ResizeWithPadOrCropd(keys=[\"image\",\"brainmask\"], spatial_size=(192, 192, 141)),\n",
    "        transforms.ScaleIntensityRangePercentilesd(keys=\"image\", lower=0.5, upper=99.5, b_min=0, b_max=1),\n",
    "        # transforms_2mm,\n",
    "    ]\n",
    ")\n",
    "val_ds = data.Dataset(data=val_files, transform=train_transforms)\n",
    "# sampler_val = DistributedSampler(val_ds, num_replicas=4, rank=rank)\n",
    "val_loader = DataLoader(val_ds, batch_size=train_batchsize, shuffle=False, num_workers=8, persistent_workers=True, drop_last=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f874efc7f204404d8d285f836a739d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549748dae86b4534b48f4ea58e987b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from diffusers import AutoencoderKLWan, WanTransformer3DModel\n",
    "model_id = \"Wan-AI/Wan2.1-T2V-14B-Diffusers\"\n",
    "vae = AutoencoderKLWan.from_pretrained(model_id, subfolder=\"vae\", torch_dtype=torch.bfloat16, cache_dir=\"/working/cache/huggingface/hub\")\n",
    "vae = vae.to(\"cuda\")\n",
    "vae.eval()\n",
    "transformer = WanTransformer3DModel.from_pretrained(model_id, subfolder=\"transformer\", torch_dtype=torch.bfloat16, cache_dir=\"/working/cache/huggingface/hub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedFlowNet(nn.Module):\n",
    "    def __init__(self, latent_dim, input_channels = 4,  drop_prob=0.1, lora = True):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_channels = input_channels\n",
    "        self.init_model(lora)\n",
    "\n",
    "    def add_lora_to_model(self, model, lora_rank=4, lora_alpha=4, lora_target_modules=\"q,k,v,o,ffn.0,ffn.2\", init_lora_weights=\"kaiming\", pretrained_lora_path=None, state_dict_converter=None):\n",
    "        # Add LoRA to UNet\n",
    "        from peft import LoraConfig, inject_adapter_in_model\n",
    "        lora_alpha = lora_alpha\n",
    "        if init_lora_weights == \"kaiming\":\n",
    "            init_lora_weights = True\n",
    "            \n",
    "        lora_config = LoraConfig(\n",
    "            r=lora_rank,\n",
    "            lora_alpha=lora_alpha,\n",
    "            init_lora_weights=init_lora_weights,\n",
    "            target_modules=lora_target_modules.split(\",\"),\n",
    "        )\n",
    "        model = inject_adapter_in_model(lora_config, model)\n",
    "        for param in model.parameters():\n",
    "            # Upcast LoRA parameters into fp32\n",
    "            if param.requires_grad:\n",
    "                param.data = param.to(torch.float32)\n",
    "        \n",
    "    def init_model(self, lora):\n",
    "        self.transformer = WanTransformer3DModel.from_pretrained(model_id, subfolder=\"transformer\", torch_dtype=torch.bfloat16, cache_dir=\"/working/cache/huggingface/hub\")\n",
    "        old_patch_embed = self.transformer.patch_embedding\n",
    "        new_patch_embed = nn.Conv3d(\n",
    "            in_channels=old_patch_embed.in_channels*8,               # 修改为新输入通道\n",
    "            out_channels=old_patch_embed.out_channels,\n",
    "            kernel_size=old_patch_embed.kernel_size,\n",
    "            stride=old_patch_embed.stride,\n",
    "            padding=old_patch_embed.padding\n",
    "        )\n",
    "        self.transformer.patch_embedding = new_patch_embed\n",
    "        old_proj_out = self.transformer.proj_out\n",
    "        new_proj_out = nn.Linear(\n",
    "            in_features=old_proj_out.in_features,\n",
    "            out_features=old_proj_out.out_features*4,            # 修改为新输出通道\n",
    "            bias=True\n",
    "        )\n",
    "        self.transformer.proj_out = new_proj_out\n",
    "        if lora:\n",
    "            self.transformer = self.add_lora_to_model(transformer, lora_rank=4, lora_alpha=4, lora_target_modules=\"to_q,to_k,to_v,to_out.0,linear_1,linear_2\", init_lora_weights=\"kaiming\", pretrained_lora_path=None, state_dict_converter=None)\n",
    "    \n",
    "    def forward(self, z_t, timestep, encoder_hidden_states=None, z_c=None):\n",
    "        B, C, D, H, W = z_t.shape\n",
    "        if encoder_hidden_states is not None:\n",
    "            encoder_hidden_states = torch.zeros([1,256,4096], device=z_t.device)\n",
    "        if z_c is None:\n",
    "            z_c_in = torch.zeros_like(z_t, device=z_t.device, dtype=z_t.dtype)\n",
    "        else:\n",
    "            # 以 drop_prob 随机丢弃\n",
    "            mask = (torch.rand(B,self.input_channels, device=z_t.device, dtype=z_t.dtype) < drop_prob).float()\n",
    "            mask = mask.unsqueeze(2)\n",
    "            mask = mask.repeat(1,1,self.latent_dim)\n",
    "            mask = mask.view(B,self.latent_dim*self.input_channels,1,1,1)\n",
    "            z_c_keep = z_c\n",
    "            z_c_zero = torch.zeros_like(z_c, device=z_t.device, dtype=z_t.dtype)\n",
    "            z_c_in = z_c_keep * (1-mask) + z_c_zero * mask\n",
    "\n",
    "        # 拼接输入\n",
    "        inp = torch.cat([z_t, z_c_in], dim=1)\n",
    "        v_pred = self.transformer(inp, timestep, encoder_hidden_states)\n",
    "        return v_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_match import FlowMatchScheduler\n",
    "scheduler = FlowMatchScheduler(shift=5, sigma_min=0.0, extra_one_step=True)\n",
    "scheduler.set_timesteps(1000, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_match import FlowMatchScheduler\n",
    "scheduler = FlowMatchScheduler(shift=5, sigma_min=0.0, extra_one_step=True)\n",
    "scheduler.set_timesteps(50, denoising_strength=1.0, shift=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 4284.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1000.)\n",
      "tensor(995.9349)\n",
      "tensor(991.7355)\n",
      "tensor(987.3949)\n",
      "tensor(982.9059)\n",
      "tensor(978.2609)\n",
      "tensor(973.4514)\n",
      "tensor(968.4685)\n",
      "tensor(963.3028)\n",
      "tensor(957.9440)\n",
      "tensor(952.3810)\n",
      "tensor(946.6020)\n",
      "tensor(940.5941)\n",
      "tensor(934.3434)\n",
      "tensor(927.8350)\n",
      "tensor(921.0526)\n",
      "tensor(913.9785)\n",
      "tensor(906.5934)\n",
      "tensor(898.8763)\n",
      "tensor(890.8046)\n",
      "tensor(882.3529)\n",
      "tensor(873.4940)\n",
      "tensor(864.1975)\n",
      "tensor(854.4304)\n",
      "tensor(844.1558)\n",
      "tensor(833.3333)\n",
      "tensor(821.9177)\n",
      "tensor(809.8591)\n",
      "tensor(797.1015)\n",
      "tensor(783.5821)\n",
      "tensor(769.2307)\n",
      "tensor(753.9683)\n",
      "tensor(737.7049)\n",
      "tensor(720.3389)\n",
      "tensor(701.7543)\n",
      "tensor(681.8182)\n",
      "tensor(660.3774)\n",
      "tensor(637.2549)\n",
      "tensor(612.2449)\n",
      "tensor(585.1064)\n",
      "tensor(555.5555)\n",
      "tensor(523.2557)\n",
      "tensor(487.8049)\n",
      "tensor(448.7180)\n",
      "tensor(405.4054)\n",
      "tensor(357.1428)\n",
      "tensor(303.0303)\n",
      "tensor(241.9355)\n",
      "tensor(172.4138)\n",
      "tensor(92.5926)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_time = []\n",
    "for progress_id, timestep in enumerate(tqdm(scheduler.timesteps)):\n",
    "    print(timestep)\n",
    "    list_time.append(timestep.item())\n",
    "    # timestep_id = torch.argmin((scheduler.timesteps - timestep).abs())\n",
    "    # sigma = scheduler.sigmas[timestep_id]\n",
    "    # sigma_ = scheduler.sigmas[timestep_id + 1]\n",
    "    # print((sigma_ - sigma))\n",
    "    # print(progress_id, timestep, scheduler.timesteps[progress_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'sigma')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list_time)\n",
    "plt.xlabel('timestep')\n",
    "plt.ylabel('sigma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([196])\n",
      "tensor([953.5104])\n"
     ]
    }
   ],
   "source": [
    "timestep_id = torch.randint(0, scheduler.num_train_timesteps, (1,))\n",
    "print(timestep_id)\n",
    "timestep = scheduler.timesteps[timestep_id]\n",
    "print(timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = torch.randn((1, 16*8, 36, 24, 24), device=\"cuda\")\n",
    "noise = torch.randn_like(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9535)\n",
      "tensor(0.2967)\n"
     ]
    }
   ],
   "source": [
    "noisy_latents = scheduler.add_noise(latents, noise, timestep)\n",
    "training_target = scheduler.training_target(latents, noise, timestep)\n",
    "weight =scheduler.training_weight(timestep)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.num_train_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_patch_embed = transformer.patch_embedding\n",
    "new_patch_embed = nn.Conv3d(\n",
    "    in_channels=old_patch_embed.in_channels*8,               # 修改为新输入通道\n",
    "    out_channels=old_patch_embed.out_channels,\n",
    "    kernel_size=old_patch_embed.kernel_size,\n",
    "    stride=old_patch_embed.stride,\n",
    "    padding=old_patch_embed.padding\n",
    ")\n",
    "transformer.patch_embedding = new_patch_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_proj_out = transformer.proj_out\n",
    "new_proj_out = nn.Linear(\n",
    "    in_features=old_proj_out.in_features,\n",
    "    out_features=old_proj_out.out_features*4,            # 修改为新输出通道\n",
    "    bias=True\n",
    ")\n",
    "transformer.proj_out = new_proj_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "for batch in train_loader:\n",
    "    image = batch['image']\n",
    "    mask = batch['brainmask']\n",
    "    path = batch['path']\n",
    "    image = image.permute(0, 1, 4, 2, 3)  # [B, C, H, W, D] -> [B, D, H, W, C]\n",
    "    B, C, D, H, W  = image.shape\n",
    "    image = image.view(B*C, D, H, W)  # [4, 1, D, H, W]\n",
    "    image = image.unsqueeze(1)\n",
    "    image = image.repeat(1, 3, 1, 1, 1)  # [4, 3, D, H, W]\n",
    "    image = image.to(torch.bfloat16).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        encode = vae.encode(image, return_dict=True)\n",
    "    latent = encode.latent_dist.sample()\n",
    "    latents = latent.view(B, 64, -1, int(H/8), int(W/8))\n",
    "\n",
    "    noise = torch.randn_like(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(1, 16*8, 36, 24, 24)  # 示例输入\n",
    "timestep = torch.tensor([0.5])  # 示例时间步\n",
    "encoder_hidden_states = torch.zeros([1,256,4096])\n",
    "device = \"cuda:1\"\n",
    "input_tensor = input_tensor.to(torch.bfloat16).to(device)\n",
    "timestep = timestep.to(torch.bfloat16).to(device)\n",
    "encoder_hidden_states = encoder_hidden_states.to(torch.bfloat16).to(device)\n",
    "transformer = transformer.to(torch.bfloat16).to(device)\n",
    "transformer.eval()\n",
    "with torch.no_grad():\n",
    "    output_tensor = transformer(input_tensor,timestep,encoder_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 1.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n",
      "torch.Size([2, 64, 1, 1, 1])\n",
      "torch.Size([2, 128, 36, 24, 24])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "drop_prob = 0.5\n",
    "B=2\n",
    "mask = (torch.rand(B,4) < drop_prob).float()\n",
    "print(mask)\n",
    "mask = mask.unsqueeze(2)\n",
    "mask = mask.repeat(1, 1,16)\n",
    "print(mask)\n",
    "mask = mask.view(B,64,1,1,1)\n",
    "temp = mask\n",
    "print(mask.shape)\n",
    "z_c = torch.randn(2, 16*4, 36, 24, 24)\n",
    "z_t = torch.randn(2, 16*4, 36, 24, 24)\n",
    "z_c_keep = z_c\n",
    "z_c_zero = torch.zeros_like(z_c)\n",
    "z_c_in = z_c_keep * (1-mask) + z_c_zero * mask\n",
    "inp = torch.cat([z_t, z_c_in], dim=1)\n",
    "print(inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4756,  1.3364, -1.8510,  ..., -0.2455,  0.8831, -2.2188],\n",
      "         [ 1.6360,  0.2115,  0.1845,  ...,  0.4757,  0.5624,  0.9984],\n",
      "         [-0.3493, -0.2139,  0.7961,  ...,  0.4748,  0.8761, -1.1175],\n",
      "         ...,\n",
      "         [-0.4544,  0.4924,  0.7404,  ...,  1.4657,  0.1157, -0.9766],\n",
      "         [-1.6039, -1.0260,  0.9928,  ..., -2.1504,  0.1625,  0.3053],\n",
      "         [-1.5007, -0.2203,  0.3625,  ...,  1.8407,  1.1935, -0.5810]],\n",
      "\n",
      "        [[ 1.3024, -0.8282,  1.5123,  ...,  1.3112,  0.0914, -0.2439],\n",
      "         [-1.0041,  0.6061, -0.7771,  ..., -2.1214, -1.2982, -0.7440],\n",
      "         [ 0.2729, -1.5970, -0.9687,  ..., -0.9695,  1.0247, -0.6627],\n",
      "         ...,\n",
      "         [-0.4088, -0.6579,  1.1653,  ..., -2.5557,  1.0464, -0.2372],\n",
      "         [-0.8993,  1.1056, -0.4442,  ...,  1.7403,  2.2419,  1.4537],\n",
      "         [-1.3701,  0.5491,  0.4437,  ..., -1.0008,  0.8541,  0.8554]],\n",
      "\n",
      "        [[-0.1559,  1.2950, -0.4012,  ..., -1.2270, -1.5531,  0.7714],\n",
      "         [ 0.0904,  0.9392,  0.0465,  ..., -2.1391,  0.3680,  1.9207],\n",
      "         [-0.8881, -0.8786,  0.5920,  ..., -1.5220,  0.2253, -0.8574],\n",
      "         ...,\n",
      "         [ 0.9461, -1.0680, -0.9642,  ...,  0.0244, -0.3137, -0.4765],\n",
      "         [ 0.1767,  1.7903, -0.1586,  ...,  0.5853,  0.3050,  0.7090],\n",
      "         [ 1.9765,  0.2344,  0.3182,  ...,  0.5920, -0.3351,  1.5124]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0356, -0.7280,  0.4453,  ..., -0.5527,  1.4185, -0.1860],\n",
      "         [-0.5358,  0.3297, -0.3028,  ..., -1.7351,  1.0049, -0.7368],\n",
      "         [-0.2970,  1.6711,  0.1143,  ...,  0.7595, -0.5952,  0.7973],\n",
      "         ...,\n",
      "         [-0.1306,  0.7366,  0.2249,  ...,  0.9647,  1.2344,  0.1252],\n",
      "         [-1.3351, -0.7565, -1.2295,  ..., -0.8259,  0.5538, -0.5649],\n",
      "         [-0.6318, -1.0481, -0.7870,  ...,  0.1846,  0.4181, -0.3132]],\n",
      "\n",
      "        [[-3.3816,  1.1479, -0.4510,  ...,  0.1284, -0.4308, -0.5235],\n",
      "         [-1.1972, -1.6637,  0.2545,  ...,  1.0184,  0.7290, -0.6098],\n",
      "         [ 0.2516, -1.9101, -0.7055,  ...,  0.6717, -0.5430, -0.8099],\n",
      "         ...,\n",
      "         [ 1.7494, -0.4055, -1.0967,  ..., -1.0950, -0.2646,  0.1498],\n",
      "         [ 1.2709,  0.0243, -0.7220,  ...,  0.9447,  0.2246, -1.9847],\n",
      "         [-1.4512,  0.7172,  0.0918,  ..., -0.2216,  0.5457,  2.1865]],\n",
      "\n",
      "        [[-0.5682, -0.6731, -1.2231,  ..., -1.6778,  0.1575,  1.2381],\n",
      "         [-1.4044,  1.5924, -1.1773,  ...,  0.8710, -0.3949,  1.9663],\n",
      "         [ 0.2227, -1.1431, -0.4124,  ...,  1.2749, -0.7865,  1.0631],\n",
      "         ...,\n",
      "         [ 0.7956,  1.3985, -1.7694,  ...,  2.5482, -0.2129, -1.0868],\n",
      "         [-1.7574, -0.3302, -0.9505,  ...,  1.0172,  0.0511, -0.8489],\n",
      "         [-0.7620,  0.2999,  0.1928,  ..., -1.0683,  0.8142, -0.2380]]])\n"
     ]
    }
   ],
   "source": [
    "print(z_c_in[0,49,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 36, 24, 24])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor.sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    image = batch['image']\n",
    "    image = image.view(4, 1, 192, 192, 144)  # [4, 1, D, H, W]\n",
    "    image = image.repeat(1, 3, 1, 1, 1)  # [4, 3, D, H, W]\n",
    "    image = image.to(torch.bfloat16).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        latent = vae.encode(image, return_dict=True).latent_dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, inject_adapter_in_model\n",
    "def add_lora_to_model(model, lora_rank=4, lora_alpha=4, lora_target_modules=\"q,k,v,o,ffn.0,ffn.2\", init_lora_weights=\"kaiming\", pretrained_lora_path=None, state_dict_converter=None):\n",
    "    # Add LoRA to UNet\n",
    "    lora_alpha = lora_alpha\n",
    "    if init_lora_weights == \"kaiming\":\n",
    "        init_lora_weights = True\n",
    "        \n",
    "    lora_config = LoraConfig(\n",
    "        r=lora_rank,\n",
    "        lora_alpha=lora_alpha,\n",
    "        init_lora_weights=init_lora_weights,\n",
    "        target_modules=lora_target_modules.split(\",\"),\n",
    "    )\n",
    "    model = inject_adapter_in_model(lora_config, model)\n",
    "    for param in model.parameters():\n",
    "        # Upcast LoRA parameters into fp32\n",
    "        if param.requires_grad:\n",
    "            param.data = param.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WanTransformer3DModel(\n",
       "  (rope): WanRotaryPosEmbed()\n",
       "  (patch_embedding): Conv3d(128, 5120, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "  (condition_embedder): WanTimeTextImageEmbedding(\n",
       "    (timesteps_proj): Timesteps()\n",
       "    (time_embedder): TimestepEmbedding(\n",
       "      (linear_1): lora.Linear(\n",
       "        (base_layer): Linear(in_features=256, out_features=5120, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=256, out_features=4, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=4, out_features=5120, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "        (lora_magnitude_vector): ModuleDict()\n",
       "      )\n",
       "      (act): SiLU()\n",
       "      (linear_2): lora.Linear(\n",
       "        (base_layer): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=5120, out_features=4, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=4, out_features=5120, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "        (lora_magnitude_vector): ModuleDict()\n",
       "      )\n",
       "    )\n",
       "    (act_fn): SiLU()\n",
       "    (time_proj): Linear(in_features=5120, out_features=30720, bias=True)\n",
       "    (text_embedder): PixArtAlphaTextProjection(\n",
       "      (linear_1): lora.Linear(\n",
       "        (base_layer): Linear(in_features=4096, out_features=5120, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=4, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=4, out_features=5120, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "        (lora_magnitude_vector): ModuleDict()\n",
       "      )\n",
       "      (act_1): GELU(approximate='tanh')\n",
       "      (linear_2): lora.Linear(\n",
       "        (base_layer): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=5120, out_features=4, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=4, out_features=5120, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "        (lora_magnitude_vector): ModuleDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-39): 40 x WanTransformerBlock(\n",
       "      (norm1): FP32LayerNorm((5120,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn1): Attention(\n",
       "        (norm_q): RMSNorm()\n",
       "        (norm_k): RMSNorm()\n",
       "        (to_q): lora.Linear(\n",
       "          (base_layer): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (default): Identity()\n",
       "          )\n",
       "          (lora_A): ModuleDict(\n",
       "            (default): Linear(in_features=5120, out_features=4, bias=False)\n",
       "          )\n",
       "          (lora_B): ModuleDict(\n",
       "            (default): Linear(in_features=4, out_features=5120, bias=False)\n",
       "          )\n",
       "          (lora_embedding_A): ParameterDict()\n",
       "          (lora_embedding_B): ParameterDict()\n",
       "          (lora_magnitude_vector): ModuleDict()\n",
       "        )\n",
       "        (to_k): lora.Linear(\n",
       "          (base_layer): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (default): Identity()\n",
       "          )\n",
       "          (lora_A): ModuleDict(\n",
       "            (default): Linear(in_features=5120, out_features=4, bias=False)\n",
       "          )\n",
       "          (lora_B): ModuleDict(\n",
       "            (default): Linear(in_features=4, out_features=5120, bias=False)\n",
       "          )\n",
       "          (lora_embedding_A): ParameterDict()\n",
       "          (lora_embedding_B): ParameterDict()\n",
       "          (lora_magnitude_vector): ModuleDict()\n",
       "        )\n",
       "        (to_v): lora.Linear(\n",
       "          (base_layer): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (default): Identity()\n",
       "          )\n",
       "          (lora_A): ModuleDict(\n",
       "            (default): Linear(in_features=5120, out_features=4, bias=False)\n",
       "          )\n",
       "          (lora_B): ModuleDict(\n",
       "            (default): Linear(in_features=4, out_features=5120, bias=False)\n",
       "          )\n",
       "          (lora_embedding_A): ParameterDict()\n",
       "          (lora_embedding_B): ParameterDict()\n",
       "          (lora_magnitude_vector): ModuleDict()\n",
       "        )\n",
       "        (to_out): ModuleList(\n",
       "          (0): lora.Linear(\n",
       "            (base_layer): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=5120, out_features=4, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=4, out_features=5120, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (attn2): Attention(\n",
       "        (norm_q): RMSNorm()\n",
       "        (norm_k): RMSNorm()\n",
       "        (to_q): lora.Linear(\n",
       "          (base_layer): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (default): Identity()\n",
       "          )\n",
       "          (lora_A): ModuleDict(\n",
       "            (default): Linear(in_features=5120, out_features=4, bias=False)\n",
       "          )\n",
       "          (lora_B): ModuleDict(\n",
       "            (default): Linear(in_features=4, out_features=5120, bias=False)\n",
       "          )\n",
       "          (lora_embedding_A): ParameterDict()\n",
       "          (lora_embedding_B): ParameterDict()\n",
       "          (lora_magnitude_vector): ModuleDict()\n",
       "        )\n",
       "        (to_k): lora.Linear(\n",
       "          (base_layer): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (default): Identity()\n",
       "          )\n",
       "          (lora_A): ModuleDict(\n",
       "            (default): Linear(in_features=5120, out_features=4, bias=False)\n",
       "          )\n",
       "          (lora_B): ModuleDict(\n",
       "            (default): Linear(in_features=4, out_features=5120, bias=False)\n",
       "          )\n",
       "          (lora_embedding_A): ParameterDict()\n",
       "          (lora_embedding_B): ParameterDict()\n",
       "          (lora_magnitude_vector): ModuleDict()\n",
       "        )\n",
       "        (to_v): lora.Linear(\n",
       "          (base_layer): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (default): Identity()\n",
       "          )\n",
       "          (lora_A): ModuleDict(\n",
       "            (default): Linear(in_features=5120, out_features=4, bias=False)\n",
       "          )\n",
       "          (lora_B): ModuleDict(\n",
       "            (default): Linear(in_features=4, out_features=5120, bias=False)\n",
       "          )\n",
       "          (lora_embedding_A): ParameterDict()\n",
       "          (lora_embedding_B): ParameterDict()\n",
       "          (lora_magnitude_vector): ModuleDict()\n",
       "        )\n",
       "        (to_out): ModuleList(\n",
       "          (0): lora.Linear(\n",
       "            (base_layer): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=5120, out_features=4, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=4, out_features=5120, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm2): FP32LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (net): ModuleList(\n",
       "          (0): GELU(\n",
       "            (proj): Linear(in_features=5120, out_features=13824, bias=True)\n",
       "          )\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "          (2): Linear(in_features=13824, out_features=5120, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm3): FP32LayerNorm((5120,), eps=1e-06, elementwise_affine=False)\n",
       "    )\n",
       "  )\n",
       "  (norm_out): FP32LayerNorm((5120,), eps=1e-06, elementwise_affine=False)\n",
       "  (proj_out): Linear(in_features=5120, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = add_lora_to_model(transformer, lora_rank=4, lora_alpha=4, lora_target_modules=\"to_q,to_k,to_v,to_out.0,linear_1,linear_2\", init_lora_weights=\"kaiming\", pretrained_lora_path=None, state_dict_converter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = batch[\"latents\"].to(self.device)\n",
    "prompt_emb = batch[\"prompt_emb\"]\n",
    "prompt_emb[\"context\"] = prompt_emb[\"context\"][0].to(self.device)\n",
    "image_emb = batch[\"image_emb\"]\n",
    "if \"clip_feature\" in image_emb:\n",
    "    image_emb[\"clip_feature\"] = image_emb[\"clip_feature\"][0].to(self.device)\n",
    "if \"y\" in image_emb:\n",
    "    image_emb[\"y\"] = image_emb[\"y\"][0].to(self.device)\n",
    "\n",
    "# Loss\n",
    "self.pipe.device = self.device\n",
    "noise = torch.randn_like(latents)\n",
    "timestep_id = torch.randint(0, self.pipe.scheduler.num_train_timesteps, (1,))\n",
    "timestep = self.pipe.scheduler.timesteps[timestep_id].to(dtype=self.pipe.torch_dtype, device=self.pipe.device)\n",
    "extra_input = self.pipe.prepare_extra_input(latents)\n",
    "noisy_latents = self.pipe.scheduler.add_noise(latents, noise, timestep)\n",
    "training_target = self.pipe.scheduler.training_target(latents, noise, timestep)\n",
    "\n",
    "# Compute loss\n",
    "noise_pred = self.pipe.denoising_model()(\n",
    "    noisy_latents, timestep=timestep, **prompt_emb, **extra_input, **image_emb,\n",
    "    use_gradient_checkpointing=self.use_gradient_checkpointing,\n",
    "    use_gradient_checkpointing_offload=self.use_gradient_checkpointing_offload\n",
    ")\n",
    "loss = torch.nn.functional.mse_loss(noise_pred.float(), training_target.float())\n",
    "loss = loss * self.pipe.scheduler.training_weight(timestep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
